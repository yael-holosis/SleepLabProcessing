{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "def process_annotations(annotation_path):\n",
    "    \"\"\"\n",
    "    Process sleep lab annotation CSV file into a structured DataFrame\n",
    "    \n",
    "    Parameters:\n",
    "    annotation_path : str or Path\n",
    "        \n",
    "    Returns:\n",
    "    pd.DataFrame\n",
    "    Processed DataFrame with columns: Start, Duration [ms], Event, Type, Stage\n",
    "    \"\"\"\n",
    "\n",
    "    pth_to_file = Path(annotation_path)\n",
    "    df = pd.read_csv(pth_to_file.as_posix())\n",
    "    df.drop(['Unnamed: 1', 'Unnamed: 2'], axis=1, inplace=True)\n",
    "    df.dropna(inplace=True)\n",
    "    pattern = r'Start: (.*?); Duration \\[ms\\]: (.*?); Event: (.*?); \\((.*?)\\)(?:; Stage: (.*))?'\n",
    "    df[['Start', 'Duration [ms]', 'Event', 'Type', 'Stage']] = df['Event-Exportdatei'].str.extract(pattern)\n",
    "    df.drop('Event-Exportdatei', axis=1, inplace=True)\n",
    "    df.drop_duplicates(inplace=True)\n",
    "    df = df.dropna(subset=['Duration [ms]'])\n",
    "    return df\n",
    "\n",
    "def convert_duration_to_indices(df, params):\n",
    "    \"\"\"\n",
    "    Convert duration from milliseconds to number of indices based on radar sampling rate\n",
    "    \n",
    "    Parameters:\n",
    "    df: DataFrame with 'Duration [ms]' column\n",
    "    params: Dictionary containing parameters including 'fps' key\n",
    "    \n",
    "    Returns:\n",
    "    DataFrame with new column 'Duration_indices'\n",
    "    \"\"\"\n",
    "    fps_respiration = params['fps']\n",
    "    df['Duration_indices'] = (df['Duration [ms]'].astype(float) / 1000 * fps_respiration).astype(int)\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "def calculate_end_times(df):\n",
    "    \"\"\"\n",
    "    Calculate end times by adding duration to start times\n",
    "    \n",
    "    Parameters:\n",
    "    df : pd.DataFrame\n",
    "        DataFrame with 'Start' column (time strings) and 'Duration [ms]' column\n",
    "        \n",
    "    Returns:\n",
    "    pd.DataFrame\n",
    "        DataFrame with new 'End' column containing end times\n",
    "    \"\"\"\n",
    "    start_times = pd.to_datetime(df['Start'], format='%H:%M:%S')\n",
    "    duration_seconds = (df['Duration [ms]'].astype(float) / 1000).round().astype(int)\n",
    "    end_times = start_times + pd.to_timedelta(duration_seconds, unit='s')\n",
    "    df['End'] = end_times.dt.strftime('%H:%M:%S')\n",
    "    return df\n",
    "\n",
    "def extract_recording_date(annotation_path):\n",
    "    \"\"\"Extract recording date from annotations CSV file.\n",
    "    Args:\n",
    "        annotation_path (str|Path): Path to annotations file\n",
    "    Returns:\n",
    "        str: Recording date (DD.MM.YYYY)\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(annotation_path, nrows=50)\n",
    "    date_row_idx = df[df.iloc[:, 0] == '[Rec. date:]'].index\n",
    "    if date_row_idx.empty:\n",
    "        raise ValueError(\"Recording date not found in file\")\n",
    "    \n",
    "    date_str = df.iloc[date_row_idx[0] + 1, 0]\n",
    "    recording_date = pd.to_datetime(date_str, format='%d.%m.%Y')\n",
    "    return recording_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "study = 'Sleep Lab'\n",
    "from aws_manager import S3Manager, DBManagerSystem\n",
    "import yaml\n",
    "import pandas as pd\n",
    "\n",
    "def fetch_motion_results(db_manager, session_id):\n",
    "    query = f\"SELECT * FROM MotionResult WHERE SessionID = {session_id}\"\n",
    "    return pd.read_sql(query, db_manager.engine)\n",
    "\n",
    "def fetch_study_sessions(db_manager, study):\n",
    "    query = f\"\"\"\n",
    "    SELECT Patient.PatientStudyName, Patient.EnrollmentTime,\n",
    "    Session.* FROM Session \n",
    "    JOIN Patient ON Session.PatientID = Patient.ID \n",
    "    JOIN Study ON Patient.StudyID = Study.ID \n",
    "    WHERE Study.Name = '{study}'\n",
    "    \"\"\"\n",
    "    return pd.read_sql(query, db_manager.engine)\n",
    "\n",
    "def find_session_id(recording_date):\n",
    "    matching_session = session_df[session_df['StartTime'].dt.date == recording_date.date()]\n",
    "    return matching_session['ID'].item()\n",
    "\n",
    "\n",
    "def fetch_radar_signals(db_manager, session_id):\n",
    "    query = f\"\"\"\n",
    "    select RadarSignal.*, RespirationHrResults.* \n",
    "    from RadarSignal \n",
    "    JOIN RespirationHrResults ON RespirationHrResults.SessionID = RadarSignal.SessionID\n",
    "    AND RespirationHrResults.SessionSignalID = RadarSignal.SessionSignalID\n",
    "    where RadarSignal.SessionID = {session_id}\n",
    "    \"\"\"\n",
    "    return pd.read_sql(query, db_manager.engine)\n",
    "\n",
    "\n",
    "def load_config():\n",
    "    with open('parameters.yaml', 'r') as file:\n",
    "        config = yaml.safe_load(file)\n",
    "    return config\n",
    "\n",
    "S3_CONFIG = load_config()['Cloud']['s3']\n",
    "DB_CONFIG = load_config()['Cloud']['DB_system']\n",
    "\n",
    "s3_manager = S3Manager(\n",
    "    access_key_id=S3_CONFIG['access_key_id'],\n",
    "    secret_access_key=S3_CONFIG['secret_access_key'],\n",
    "    region=S3_CONFIG['region'],\n",
    "    bucket_name=S3_CONFIG['bucket_name']\n",
    ")\n",
    "\n",
    "db_manager = DBManagerSystem(\n",
    "    host=DB_CONFIG['host'],\n",
    "    \n",
    "    user=DB_CONFIG['user'],\n",
    "    password=DB_CONFIG['password'],\n",
    "    database=DB_CONFIG['database']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_signal_id(object):\n",
    "    id_string = str(object)\n",
    "    # Split the string by lines\n",
    "    lines = id_string.split('\\n')\n",
    "    # From the first line, get the value after \"SessionSignalID\"\n",
    "    if lines and \"SessionSignalID\" in lines[0]:\n",
    "        # Split by whitespace and get the last part\n",
    "        parts = lines[0].split()\n",
    "        if len(parts) > 1:\n",
    "            return parts[-1].strip()\n",
    "    return \"Unknown\"  \n",
    "\n",
    "def divide_annotations_by_signals(annotations_df, signals_df, recording_date, fps=200, labeler_id='SML'):\n",
    "    \"\"\"Divide annotations into different radar signals based on start and end times.\n",
    "    Args:\n",
    "        annotations_df (pd.DataFrame): DataFrame with annotations\n",
    "        signals_df (pd.DataFrame): DataFrame with signal start and end times\n",
    "        recording_date (datetime): Date when the recording started\n",
    "        fps (int): Frames per second (default is 200)\n",
    "        labeler_id (str): ID of the labeler\n",
    "    Returns:\n",
    "        pd.DataFrame: New DataFrame with first and last signal IDs\n",
    "    \"\"\"\n",
    "\n",
    "    annotations = annotations_df.copy()\n",
    "    signals = signals_df.copy()\n",
    "    annotations['Duration [ms]'] = pd.to_numeric(annotations['Duration [ms]'], errors='coerce')\n",
    "    time_strings = annotations['Start'].astype(str)\n",
    "    start_times = []\n",
    "    for time_str in time_strings:\n",
    "        hours = int(time_str.split(':')[0])\n",
    "        if hours >= 12 and hours <= 23: # Evening times \n",
    "            date_to_use = recording_date\n",
    "        else:\n",
    "            date_to_use = recording_date + pd.Timedelta(days=1)    # Morning times\n",
    "        dt = pd.to_datetime(f\"{date_to_use.strftime('%Y-%m-%d')} {time_str}\")\n",
    "        start_times.append(dt)\n",
    "    \n",
    "    annotations['Start'] = start_times\n",
    "    \n",
    "    # Handle NaN durations - set End time equal to Start time for crosshair effect\n",
    "    annotations['End'] = annotations.apply(\n",
    "        lambda row: row['Start'] if pd.isna(row['Duration [ms]']) \n",
    "                    else row['Start'] + pd.Timedelta(seconds=row['Duration [ms]']/1000),axis=1)\n",
    "    \n",
    "    \n",
    "    signals['StartTime'] = pd.to_datetime(signals['StartTime'])\n",
    "    signals['EndTime'] = pd.to_datetime(signals['EndTime'])\n",
    "    \n",
    "  \n",
    "    results = []\n",
    "    for idx, annotation in annotations.iterrows():\n",
    "        matching_signals = []\n",
    "        for sig_idx, signal in signals.iterrows():\n",
    "            # Check for overlap\n",
    "            if annotation['End'] <= signal['StartTime'] or annotation['Start'] >= signal['EndTime']:\n",
    "                continue  # No overlap\n",
    "            signal_id = extract_signal_id(signal.SessionSignalID)\n",
    "            overlap_start = max(annotation['Start'], signal['StartTime'])\n",
    "            overlap_end = min(annotation['End'], signal['EndTime'])\n",
    "            matching_signals.append((signal_id, overlap_start, overlap_end, signal['StartTime']))\n",
    "        \n",
    "        # If we found matching signals\n",
    "        if matching_signals:\n",
    "            matching_signals.sort(key=lambda x: x[1])\n",
    "            first_signal = matching_signals[0]\n",
    "            last_signal = matching_signals[-1]\n",
    "            # Calculate indices for first signal\n",
    "            if annotation['Start'] == annotation['End']:  # Crosshair\n",
    "                start_index = int((first_signal[1] - first_signal[3]).total_seconds() * fps)\n",
    "                first_end_index = start_index\n",
    "            else:\n",
    "                start_index = int((first_signal[1] - first_signal[3]).total_seconds() * fps)\n",
    "                first_end_index = int((first_signal[2] - first_signal[3]).total_seconds() * fps)\n",
    "            # Calculate indices for last signal\n",
    "            if annotation['Start'] == annotation['End']:  # Crosshair\n",
    "                last_start_index = int((last_signal[1] - last_signal[3]).total_seconds() * fps)\n",
    "                end_index = last_start_index\n",
    "            else:\n",
    "                last_start_index = int((last_signal[1] - last_signal[3]).total_seconds() * fps)\n",
    "                end_index = int((last_signal[2] - last_signal[3]).total_seconds() * fps)\n",
    "            \n",
    "            # Add to results\n",
    "            results.append({\n",
    "                'FirstSignalID': first_signal[0],\n",
    "                'LastSignalID': last_signal[0],\n",
    "                'EventTypeID': annotation['Event'],\n",
    "                'StartIndex': start_index,\n",
    "                'EndIndex': end_index,\n",
    "                'TimeStamp': annotation['Start'],\n",
    "                'LabelerID': labeler_id })\n",
    "    \n",
    "    # Create the DataFrame\n",
    "    divided_df = pd.DataFrame(results)\n",
    "    print(f\"Total annotations processed: {len(divided_df)}\")\n",
    "    \n",
    "    return divided_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'fps': 200}  \n",
    "annotations_df = process_annotations('/Users/avitalv/Downloads/0010.csv')\n",
    "annotations_df = convert_duration_to_indices(annotations_df, params)\n",
    "annotations_df = calculate_end_times(annotations_df)\n",
    "recording_date = extract_recording_date('/Users/avitalv/Downloads/0010.csv')\n",
    "session_df = fetch_study_sessions(db_manager, study)\n",
    "session_id = find_session_id(recording_date)\n",
    "signals_df = fetch_radar_signals(db_manager, session_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "divided_df = divide_annotations_by_signals(annotations_df, signals_df, recording_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "divided_df[divided_df['FirstSignalID'] == divided_df['LastSignalID'] ]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
